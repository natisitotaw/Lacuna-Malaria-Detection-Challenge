{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-10T19:53:29.605168Z","iopub.status.busy":"2024-10-10T19:53:29.604190Z","iopub.status.idle":"2024-10-10T19:53:35.512878Z","shell.execute_reply":"2024-10-10T19:53:35.511931Z","shell.execute_reply.started":"2024-10-10T19:53:29.605116Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from PIL import Image\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms as transforms\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-10T19:53:35.514883Z","iopub.status.busy":"2024-10-10T19:53:35.514404Z","iopub.status.idle":"2024-10-10T19:53:35.727039Z","shell.execute_reply":"2024-10-10T19:53:35.725859Z","shell.execute_reply.started":"2024-10-10T19:53:35.514847Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training samples: 18824\n","Number of validation samples: 4706\n","Number of test samples: 1178\n","\n","Class distribution in training data:\n","class\n","Trophozoite    0.673077\n","WBC            0.297652\n","NEG            0.029271\n","Name: proportion, dtype: float64\n","\n","Class distribution in validation data:\n","class\n","Trophozoite    0.673183\n","WBC            0.297705\n","NEG            0.029112\n","Name: proportion, dtype: float64\n"]}],"source":["# Load CSV files\n","train_df = pd.read_csv('/kaggle/input/lacuna-malaria-detection-dataset/Train.csv')\n","test_df = pd.read_csv('/kaggle/input/lacuna-malaria-detection-dataset/Test.csv')\n","\n","# Set the image directory\n","img_dir = '/kaggle/input/lacuna-malaria-detection-dataset/images/'\n","\n","# Create image paths for training data\n","train_df['image_path'] = train_df['Image_ID'].apply(lambda x: os.path.join(img_dir, x))\n","\n","# Split training data into train and validation sets\n","train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['class'])\n","\n","# Data augmentation and normalization\n","train_transforms = transforms.Compose([\n","    transforms.RandomRotation(15),\n","    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(brightness=0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet normalization\n","])\n","\n","val_test_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","class MalariaDataset(Dataset):\n","    def __init__(self, dataframe, transform=None):\n","        self.dataframe = dataframe\n","        self.transform = transform\n","        \n","        # Create a class-to-index mapping\n","        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(dataframe['class'].unique())}\n","        \n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.dataframe.iloc[idx]['image_path']\n","        image = Image.open(img_path).convert('RGB')\n","        \n","        # Get label and map it to an integer using the class-to-index mapping\n","        label = self.dataframe.iloc[idx]['class']\n","        label = self.class_to_idx[label]  # Convert class name to index\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","        \n","        # Convert label to tensor\n","        label = torch.tensor(label, dtype=torch.long)\n","        \n","        return image, label\n","\n","\n","\n","# Create Datasets and DataLoaders\n","batch_size = 32\n","\n","train_dataset = MalariaDataset(train_data, transform=train_transforms)\n","val_dataset = MalariaDataset(val_data, transform=val_test_transforms)\n","test_dataset = MalariaDataset(test_df, transform=val_test_transforms)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Print some information about the data\n","print(f\"Number of training samples: {len(train_dataset)}\")\n","print(f\"Number of validation samples: {len(val_dataset)}\")\n","print(f\"Number of test samples: {len(test_dataset)}\")\n","\n","# Check class balance\n","print(\"\\nClass distribution in training data:\")\n","print(train_data['class'].value_counts(normalize=True))\n","print(\"\\nClass distribution in validation data:\")\n","print(val_data['class'].value_counts(normalize=True))\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-10T19:53:43.701876Z","iopub.status.busy":"2024-10-10T19:53:43.701453Z","iopub.status.idle":"2024-10-10T19:53:43.743236Z","shell.execute_reply":"2024-10-10T19:53:43.742201Z","shell.execute_reply.started":"2024-10-10T19:53:43.701836Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-10T19:54:01.010587Z","iopub.status.busy":"2024-10-10T19:54:01.009634Z","iopub.status.idle":"2024-10-10T19:54:01.783072Z","shell.execute_reply":"2024-10-10T19:54:01.782076Z","shell.execute_reply.started":"2024-10-10T19:54:01.010546Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n","100%|██████████| 20.5M/20.5M [00:00<00:00, 112MB/s] \n"]}],"source":["import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.models import efficientnet_b0\n","\n","# Load pretrained EfficientNet model\n","model = efficientnet_b0(pretrained=True)\n","model.classifier = nn.Sequential(\n","    nn.Dropout(p=0.2),\n","    nn.Linear(model.classifier[1].in_features, 3)  # Assuming 3 classes\n",")\n","\n","# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# **Training and Validation**\n","\n","def train_model(model, train_loader, val_loader, num_epochs=10):\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        correct = 0\n","        total = 0\n","\n","        for images, labels in train_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","            _, predicted = torch.max(outputs, 1)\n","            correct += (predicted == labels).sum().item()\n","            total += labels.size(0)\n","\n","        train_accuracy = 100 * correct / total\n","        val_accuracy = evaluate_model(model, val_loader)\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/total:.4f}, Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%')\n","\n","def evaluate_model(model, val_loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            correct += (predicted == labels).sum().item()\n","            total += labels.size(0)\n","\n","    return 100 * correct / total"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-10T19:54:04.832236Z","iopub.status.busy":"2024-10-10T19:54:04.831848Z"},"trusted":true},"outputs":[],"source":["train_model(model, train_loader, val_loader, num_epochs=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def test_model(model, test_loader):\n","    # Set the model to evaluation mode (disables dropout, batch norm, etc.)\n","    model.eval()\n","    \n","    # Initialize an empty list to store predictions\n","    predictions = []\n","    \n","    # Disable gradient calculation to save memory and speed up computation\n","    with torch.no_grad():\n","        # Iterate over the test data (batches of images)\n","        for images in test_loader:\n","            # Move images to the specified device (e.g., GPU if available)\n","            images = images.to(device)\n","            \n","            # Perform forward pass to get model outputs\n","            outputs = model(images)\n","            \n","            # Get the index of the max logit (the predicted class) along dimension 1\n","            _, predicted = torch.max(outputs, 1)\n","            \n","            # Convert predictions to a NumPy array and store them in the list\n","            predictions.extend(predicted.cpu().numpy())\n","    \n","    # Return the list of predictions for all test samples\n","    return predictions\n","\n","# Call the function to get predictions for the test set\n","test_predictions = test_model(model, test_loader)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["results_df = pd.DataFrame({\n","    'Image_ID': test_df['Image_ID'],\n","    'Predicted_Class': test_predictions\n","})\n","\n","results_df.head()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5783394,"sourceId":9502706,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}

{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9502706,"sourceType":"datasetVersion","datasetId":5783394}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-10-10T19:53:29.604190Z","iopub.execute_input":"2024-10-10T19:53:29.605168Z","iopub.status.idle":"2024-10-10T19:53:35.512878Z","shell.execute_reply.started":"2024-10-10T19:53:29.605116Z","shell.execute_reply":"2024-10-10T19:53:35.511931Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Load CSV files\ntrain_df = pd.read_csv('/kaggle/input/lacuna-malaria-detection-dataset/Train.csv')\ntest_df = pd.read_csv('/kaggle/input/lacuna-malaria-detection-dataset/Test.csv')\n\n# Set the image directory\nimg_dir = '/kaggle/input/lacuna-malaria-detection-dataset/images/'\n\n# Create image paths for training data\ntrain_df['image_path'] = train_df['Image_ID'].apply(lambda x: os.path.join(img_dir, x))\n\n# Split training data into train and validation sets\ntrain_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['class'])\n\n# Data augmentation and normalization\ntrain_transforms = transforms.Compose([\n    transforms.RandomRotation(15),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet normalization\n])\n\nval_test_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nclass MalariaDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n        \n        # Create a class-to-index mapping\n        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(dataframe['class'].unique())}\n        \n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_path = self.dataframe.iloc[idx]['image_path']\n        image = Image.open(img_path).convert('RGB')\n        \n        # Get label and map it to an integer using the class-to-index mapping\n        label = self.dataframe.iloc[idx]['class']\n        label = self.class_to_idx[label]  # Convert class name to index\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        # Convert label to tensor\n        label = torch.tensor(label, dtype=torch.long)\n        \n        return image, label\n\n\n\n# Create Datasets and DataLoaders\nbatch_size = 32\n\ntrain_dataset = MalariaDataset(train_data, transform=train_transforms)\nval_dataset = MalariaDataset(val_data, transform=val_test_transforms)\ntest_dataset = MalariaDataset(test_df, transform=val_test_transforms)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Print some information about the data\nprint(f\"Number of training samples: {len(train_dataset)}\")\nprint(f\"Number of validation samples: {len(val_dataset)}\")\nprint(f\"Number of test samples: {len(test_dataset)}\")\n\n# Check class balance\nprint(\"\\nClass distribution in training data:\")\nprint(train_data['class'].value_counts(normalize=True))\nprint(\"\\nClass distribution in validation data:\")\nprint(val_data['class'].value_counts(normalize=True))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T19:53:35.514404Z","iopub.execute_input":"2024-10-10T19:53:35.514883Z","iopub.status.idle":"2024-10-10T19:53:35.727039Z","shell.execute_reply.started":"2024-10-10T19:53:35.514847Z","shell.execute_reply":"2024-10-10T19:53:35.725859Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of training samples: 18824\nNumber of validation samples: 4706\nNumber of test samples: 1178\n\nClass distribution in training data:\nclass\nTrophozoite    0.673077\nWBC            0.297652\nNEG            0.029271\nName: proportion, dtype: float64\n\nClass distribution in validation data:\nclass\nTrophozoite    0.673183\nWBC            0.297705\nNEG            0.029112\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-10T19:53:43.701453Z","iopub.execute_input":"2024-10-10T19:53:43.701876Z","iopub.status.idle":"2024-10-10T19:53:43.743236Z","shell.execute_reply.started":"2024-10-10T19:53:43.701836Z","shell.execute_reply":"2024-10-10T19:53:43.742201Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.models import efficientnet_b0\n\n# Load pretrained EfficientNet model\nmodel = efficientnet_b0(pretrained=True)\nmodel.classifier = nn.Sequential(\n    nn.Dropout(p=0.2),\n    nn.Linear(model.classifier[1].in_features, 3)  # Assuming 3 classes\n)\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# **Training and Validation**\n\ndef train_model(model, train_loader, val_loader, num_epochs=10):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n        train_accuracy = 100 * correct / total\n        val_accuracy = evaluate_model(model, val_loader)\n\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/total:.4f}, Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%')\n\ndef evaluate_model(model, val_loader):\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n    return 100 * correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-10T19:54:01.009634Z","iopub.execute_input":"2024-10-10T19:54:01.010587Z","iopub.status.idle":"2024-10-10T19:54:01.783072Z","shell.execute_reply.started":"2024-10-10T19:54:01.010546Z","shell.execute_reply":"2024-10-10T19:54:01.782076Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|██████████| 20.5M/20.5M [00:00<00:00, 112MB/s] \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"train_model(model, train_loader, val_loader, num_epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-10T19:54:04.831848Z","iopub.execute_input":"2024-10-10T19:54:04.832236Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_model(model, test_loader):\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for images in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            predictions.extend(predicted.cpu().numpy())\n    return predictions\n\ntest_predictions = test_model(model, test_loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df = pd.DataFrame({\n    'Image_ID': test_df['Image_ID'],\n    'Predicted_Class': test_predictions\n})\n\nresults_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}